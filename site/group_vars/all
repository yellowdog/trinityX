---
# This file contains variables that are global to all playbooks
# in this repository.

# Trinity version number

trix_version: '11'


# Project ID or string that'll show up in the default
# prompt on the controllers.

project_id: '000000'


# Do we want HA?
# Set to 'False' to disable HA, set to 'True' to enable it.

ha: false


# Should we use content of the installation CD/USB-stick
# to install TrinityX

local_install: false


# A domain name to be assigned to the controller(s) and nodes
# on the internal network.
# Luna's provisioning network name will be set to the same value.

trix_domain: cluster

# Default hostname and IP for the controller
# In an HA pair, those are the hostname and IP for the first controller.
# Those variables are required, with or without HA.

trix_ctrl1_ip: 192.168.0.4
trix_ctrl1_bmcip: 10.148.255.254
trix_ctrl1_heartbeat_ip: 10.146.255.254
trix_ctrl1_hostname: controller1

# In a non-HA setup, all of the following variables will be ignored:
# - the variables for CTRL will be set to the same as CTRL1;
# - the variables for CTRL2 will be ignored.

# Hostname and IP of the second controller

trix_ctrl2_ip: 10.141.255.253
trix_ctrl2_bmcip: 10.148.255.253
trix_ctrl2_heartbeat_ip: 10.146.255.253
trix_ctrl2_hostname: controller2

# Floating hostname and IP

trix_ctrl_ip: 10.141.255.252
trix_ctrl_hostname: controller

# Internal network definitions and the DHCP range used to to PXE boot
# the compute nodes.

trix_cluster_net: 192.168.0.0
trix_cluster_netprefix: 16
trix_cluster_dhcp_start: 10.141.128.0
trix_cluster_dhcp_end: 10.141.140.0


# Path to which the standard TrinityX files will be installed.
# If not set, it will default to /trinity

trix_root: '/trinity'

# The TrinityX root contains multiple subdirectories for different uses:
# - trix_images For the compute node images
# - trix_shared for everything shared by the controllers to the nodes
# - trix_local for configuration files specific to each machine
# - trix_home for the user home directories
#
# By default those exist under trix_root. There are some cases where this is not
# desirable; the following variables allow you to override the default paths.
# WARNING: use with caution! It's not well tested and there may be some issues
# here and there...

trix_images: '{{ trix_root }}/images'
trix_shared: '{{ trix_root }}/shared'
trix_local: '{{ trix_root }}/local'
trix_home: '{{ trix_root }}/home'
trix_repos: '{{ trix_root }}/repos'
trix_ohpc: '{{ trix_root }}/ohpc'


# Heat stuff
heat:
  ctrl_ip: '{{ trix_ctrl_ip }}'
  ctrl_hostname: '{{ trix_ctrl_hostname }}'
  static_compute_partition_name: defq
  static_compute_host_name_base: node
  static_compute_start_number: 1
  static_compute_initial_number: 20
  static_compute_max_number: 20
  static_compute_min_number: 1

# Backend type and block device to use for the specified backend.

shared_fs_type: 'drbd'
shared_fs_device: '/dev/vdb'

# Default search domains to be added to /etc/resolv.conf

resolv_search_domains: '{{ trix_domain }} ipmi'

# Default firewalld configuration
# Only public tcp/udp ports are allowed on the public interfaces
# whereas everything is allowed on the trusted interfaces

firewalld_public_interfaces: []
firewalld_trusted_interfaces: ['{{ ansible_default_ipv4.interface }}']
firewalld_public_tcp_ports: []

# All of the following are variables that override values for roles
# that are only applied as a dependency for another role.

# Default MongoDB data path. Dependency of the luna role.

mongo_db_path: '{{ trix_local }}/var/lib/mongodb'


# Path in which the generated certificates for the cluster will be installed.
# ssl_cert_group refers to the UNIX group that has read access to the certs.

ssl_cert_path: '{{ trix_local }}/etc/ssl'
ssl_ca_cert: '{{ ssl_cert_path }}/cluster-ca.crt'
ssl_cert_group: ssl


# The following variables give the ability to enable or disable
# certain features in TrinityX:

# Whether or not to enable SELinux throughout the cluster

enable_selinux: false

# Whether or not to enable Slurm PAM module
# If enabled, sssd's ldap filters will be disabled on the compute nodes

enable_slurm_pam: true

# Whether or not to configure the corosync heartbeat link (ring 1)

enable_heartbeat_link: true

# Install docker daemon, registry and utilities on the cluster

enable_docker: false

# allow ssh password login by default (set to yes or no not true or false)
allow_password_login: 'yes'

# List of additional environment modules to install

additional_env_modules: []

# Install userspace packages from OpenHPC project

enable_openhpc: true

# populate the zones from inventory

# the following settings are essential if not using luna, they tell ansible to take over configuring resolv.conf on all nodes and dns zones on on the controller and rename compute instances

configure_resolveconf: true
build_zones_from_inventory: true
use_inventory_hostname: true

# use aws NFS instance for cloud controllers

use_aws_nfs: false
# fix CentOS version if using the vault repo, otherwise set this to the current version so that you get the right mlnx ofed version for your kernel
centos_vers: 7.7
centos_fullvers: '{{centos_vers}}.1810'
use_centos_vault: false

# set mellanox OFED Defaults rembember you can override per node type in group_vars/<group>
use_mellanox_ofed: false
mellanox_version: 'latest'
mellanox_os_ver: 'rhel{{centos_vers}}'

# Local yum repository

trix_local_reponame: 'trinityx-local'
repos_port: 8080
trix_local_repo_baseurl: 'http://{{ trix_ctrl_ip }}:{{ repos_port }}/repos/trinityx/'

# Repositories to use

luna_repo: 'https://updates.clustervision.com/luna/1.2/centos/luna-1.2.repo'
trinity_repo: 'https://updates.clustervision.com/trinity/10.2/centos/trinity.repo'
userspace_repo: 'https://updates.clustervision.com/userspace/userspace-release.x86_64.rpm'
elrepo_repo: 'http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm'
zabbix_repo: https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm
ood_repo: https://yum.osc.edu/ondemand/1.6/ondemand-release-web-1.6-1.el7.noarch.rpm
ohpc_repo_dict: { repo: 'http://build.openhpc.community/OpenHPC:/1.3/CentOS_7/OpenHPC:1.3.repo', remote_key: 'http://build.openhpc.community/OpenHPC:/1.3/CentOS_7/repodata/repomd.xml.key' }
ohpc_updates_repo_dict: { repo: 'http://build.openhpc.community/OpenHPC:/1.3/updates/CentOS_7/OpenHPC:1.3:Update8.repo', remote_key: 'http://build.openhpc.community/OpenHPC:/1.3:/Update8/CentOS_7/repodata/repomd.xml.key' }
mellanox_repo_dict: { repo: 'http://linux.mellanox.com/public/repo/mlnx_ofed/{{mellanox_version}}/{{mellanox_os_ver}}/mellanox_mlnx_ofed.repo',  remote_key: 'http://www.mellanox.com/downloads/ofed/RPM-GPG-KEY-Mellanox' }

enable_repomirror: false

#example of a repomirror true config would be:
#repomirror: 'http://repomirror'
#centos_repo_dict: { repo: '{{repomirror}}/CentOS/CentOS-Base.repo', remote_key: '{{repomirror}}/RPM-GPG-KEY-CentOS-7'}
#epel_repo_dict: { repo: '{{repomirror}}/epel/epel.repo', remote_key: '{{repomirror}}/RPM-GPG-KEY-EPEL-7' }
#luna_repo: '{{repomirror}}/luna/luna-1.2.repo'
#trinity_repo: '{{repomirror}}/trinity/trinity.repo'
#zabbix_repo: '{{repomirror}}/zabbix/zabbix.repo'
#mellanox_repo_dict: { repo: '{{repomirror}}/mlnx_ofed_4.6-1.0.1.1_base/mellanox_mlnx_ofed.repo', remote_key: '{{repomirror}}/RPM-GPG-KEY-Mellanox' }
#ood_repo_dict: { repo: '{{repomirror}}/ondemand-compute/ondemand-compute.repo', remote_key: '{{repomirror}}/RPM-GPG-KEY-ondemand-compute' }
#sclo_rh_repo_dict: { repo: '{{repomirror}}/CentOS-SCLo-scl-rh.repo', remote_key: '{{repomirror}}/RPM-GPG-KEY-CentOS-SIG-SCLo' }
#ohpc_repo_dict: { repo: '{{repomirror}}/OpenHPC_1.3/OpenHPC_1.3.repo', remote_key: '{{repomirror}}/RPM-GPG-KEY-OpenHPC_1.3' }
#ohpc_updates_repo_dict: { repo: '{{repomirror}}/OpenHPC_1.3_Update8/OpenHPC_1.3_Update8.repo', remote_key: '{{repomirror}}/RPM-GPG-KEY-OpenHPC_1.3' }
